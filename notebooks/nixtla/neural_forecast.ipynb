{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-17T17:15:07.465121Z",
     "start_time": "2025-11-17T17:15:03.480735Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch as torch\n",
    "from neuralforecast.auto import AutoRNN, AutoLSTM\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T17:15:09.641337Z",
     "start_time": "2025-11-17T17:15:09.629081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "\n",
    "df = pd.read_csv('../data/SBER_250914_250915.csv', sep=';')\n",
    "\n",
    "df[\"date_str\"]=df[\"<DATE>\"].apply(lambda x: str(x).zfill(6)).astype(str)\n",
    "df[\"time_str\"]=df[\"<TIME>\"].apply(lambda x: str(x).zfill(6)).astype(str)\n",
    "df[\"datetime_str\"]=df[\"date_str\"]+df[\"time_str\"]\n",
    "df[\"ds\"]= pd.to_datetime(df[\"datetime_str\"], format='%y%m%d%H%M%S', utc=True)\n",
    "df[\"unique_id\"] = \"SBER\"\n",
    "\n",
    "df.drop([\"date_str\", \"time_str\", \"datetime_str\", \"<DATE>\", \"<TIME>\", \"<OPEN>\", \"<HIGH>\", \"<LOW>\", \"<VOL>\"], axis=1, inplace=True)\n",
    "df.rename(columns={\"<CLOSE>\": \"y\"}, inplace=True)\n",
    "\n",
    "df = df.tail(200)\n",
    "\n",
    "dataset, *_ = TimeSeriesDataset.from_df(df)"
   ],
   "id": "7b1211722ada437b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "4ef1c2961c0eac51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "config = dict(max_steps=1, val_check_steps=1, input_size=5, encoder_hidden_size=8)\n",
    "model = AutoLSTM(h=1, config=config, num_samples=1, verbose=False)\n",
    "\n",
    "model.fit(dataset=dataset)\n",
    "y_hat = model.predict(dataset=dataset)\n"
   ],
   "id": "3e48d1a5625461c2",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(_train_tune pid=63416)\u001B[0m C:\\envs\\vertr\\Lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m Seed set to 1\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m GPU available: True (cuda), used: True\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m TPU available: False, using: 0 TPU cores\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m `Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m \n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m   | Name         | Type          | Params | Mode \n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m -------------------------------------------------------\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 0 | loss         | MAE           | 0      | train\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 3 | hist_encoder | LSTM          | 928    | train\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 4 | mlp_decoder  | MLP           | 1.3 K  | train\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m -------------------------------------------------------\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 2.2 K     Trainable params\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 0         Non-trainable params\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 2.2 K     Total params\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 0.009     Total estimated model params size (MB)\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 10        Modules in train mode\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m 0         Modules in eval mode\n",
      "2025-11-17 20:15:24,425\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/A/ray_results/_train_tune_2025-11-17_20-15-12' in 0.0050s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "\u001B[36m(_train_tune pid=63416)\u001B[0m `Trainer.fit` stopped: `max_steps=1` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | eval \n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 928    | train\n",
      "4 | mlp_decoder  | MLP           | 1.3 K  | train\n",
      "-------------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "1         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=0, train_loss_step=3.960]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 333.54it/s]\u001B[A\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=0, train_loss_step=3.960, valid_loss=0.190, train_loss_epoch=3.960]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33bccc4667ac41beab4a69a973dc1bdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2aaf9752c5214b0ea3c48469ea6b5cd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ecaddb276ace4877b5ab1e984785778a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45c4f454dd29446d8341f1b20067110b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T17:15:32.363483Z",
     "start_time": "2025-11-17T17:15:32.359459Z"
    }
   },
   "cell_type": "code",
   "source": "y_hat\n",
   "id": "16980fc30c9d3de3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[302.37036]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
